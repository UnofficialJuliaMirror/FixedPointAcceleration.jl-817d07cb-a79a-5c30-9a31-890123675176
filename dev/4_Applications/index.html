<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>4.0 Applications · FixedPointAcceleration</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>FixedPointAcceleration</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">FixedPointAcceleration.jl</a></li><li><a class="toctext" href="../1_FixedPoints/">1 Fixed point acceleration</a></li><li><a class="toctext" href="../2_Algorithms/">2 Acceleration algorithms</a></li><li><a class="toctext" href="../3_UsingAdvice/">3.  Using the FixedPointAcceleration package</a></li><li class="current"><a class="toctext" href>4.0 Applications</a><ul class="internal"><li><a class="toctext" href="#.1-Finding-equilibrium-prices-in-a-pure-exchange-economy-1">4.1 Finding equilibrium prices in a pure exchange economy</a></li><li><a class="toctext" href="#.2-The-Perceptron-Classifier-1">4.2 The Perceptron Classifier</a></li><li><a class="toctext" href="#.3-Expectation-Maximisation-1">4.3 Expectation Maximisation</a></li><li><a class="toctext" href="#.4-A-consumption-smoothing-problem-1">4.4 A consumption smoothing problem</a></li></ul></li><li><a class="toctext" href="../99_refs/">References</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>4.0 Applications</a></li></ul><a class="edit-page" href="https://github.com/s-baumann/FixedPointAcceleration.jl/blob/master/docs/src/4_Applications.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>4.0 Applications</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id=".0-Applications-1" href="#.0-Applications-1">4.0 Applications</a></h1><h2><a class="nav-anchor" id=".1-Finding-equilibrium-prices-in-a-pure-exchange-economy-1" href="#.1-Finding-equilibrium-prices-in-a-pure-exchange-economy-1">4.1 Finding equilibrium prices in a pure exchange economy</a></h2><p>Consider that there are N households in a pure exchange economy. Every household has preferences over G types of good. Household <span>$n$</span> has a utility function of</p><div>\[U_n = \sum_{i=1}^G \gamma_{n,i} \log(c_{n,i})\]</div><p>Where <span>$\gamma_{n,i}$</span> is a parameter describing household <span>$n$</span>&#39;s taste for good <span>$i$</span>, <span>$c_{n,i}$</span> is household <span>$n$</span>&#39;s consumption of good <span>$i$</span>. Each household is endowed with an amount of each good. They can then trade goods before consumption. We want to find the equilibrium prices in this exchange economy. We have data on each household&#39;s endowment and preferences for each good and want to determine the equilibrium prices for this pure exchange economy.</p><p>We will choose good 1 as the numeraire. So <span>$P_1 = 1$</span>. First we will find an expression for demand given a price vector. Setting up the lagrangian for household <span>$n$</span>:</p><div>\[L_n = \sum_{i=1}^G \gamma_{n,i} \log(c_{n,i}) + \lambda_{n}[ \sum_{i=1}^G p_i(e_{n,i}-c_{n,i}) ]\]</div><p>Where <span>$\lambda_{n}$</span> is household <span>$n$</span>&#39;s shadow price and <span>$e_{n,i}$</span> is this household&#39;s endowment of good <span>$i$</span> and <span>$p_i$</span> is the price of good <span>$i$</span>. Taking FOC with respect to <span>$c_i$</span> of this lagrangian yields:</p><div>\[c_{n,i} = \frac{\gamma_{n,i}}{p_i \lambda_n}\]</div><p>and taking FOC condition with respect to <span>$\lambda_n$</span> yields the budget constraint. Subbing the above equation into the budget constrain and rearranging yields:</p><div>\[\lambda_n = \frac{\sum^G_{i=1} \gamma_{n,i}}{\sum^G_{i=1} p_i e_{n,i}}\]</div><p>We can also sum over households to find total demand for each good as:</p><div>\[D_i = \frac{1}{P_i} \sum_{n=1}^G \frac{\gamma_{n,i}}{\lambda_n}\]</div><p>We will find the equilibrium price vector by using an approximate price vector to find the <span>$\lambda$</span>s. We can then find an estimate of the equilibrium price <span>$P_i$</span> which solves <span>$D_i = \sum_{n=1}^G e_{n,i}$</span>:</p><div>\[P_i = \frac{\sum_{n=1}^G e_{n,i}}{\sum_{n=1}^G \frac{\gamma_{n,i}}{\lambda_n} }\]</div><p>We use this approach in the code below for the case of 10 goods with 8 households. For exposition sake we generate some data below before proceeding to find the equilibrium price vector.</p><pre><code class="language-none"># Generating data
using Distributions
using FixedPointAcceleration
using Random
Random.seed!(1234)
N = 5
G = 10
Endowments = rand(LogNormal(), G, N)
Tastes      = rand(G, N)  
# Every column here represents a household and every row is a good. So Endowments[1,2] is
# the second household&#39;s endowment of good 1.

# We now start solving for equilibrium prices:
TotalEndowmentsPerGood = mapslices(sum, Endowments; dims = [2])
TotalTastesPerHousehold = mapslices(sum, Tastes; dims = [1])

function LambdasGivenPriceVector(prices)
    ValueOfEndowmentsPerHousehold = prices .* Endowments
    TotalValueOfEndowmentsPerHousehold =  mapslices(sum, ValueOfEndowmentsPerHousehold; dims = [1])
    return TotalTastesPerHousehold ./ TotalValueOfEndowmentsPerHousehold
end

function IterateOnce(prices)
    Lambdas = LambdasGivenPriceVector(prices)
    TastesOverLambdas = Tastes ./ Lambdas
    SumTastesOverLambdas = mapslices(sum, TastesOverLambdas; dims = [2])
    NewPrices = SumTastesOverLambdas ./ TotalEndowmentsPerGood
    NewPrices = NewPrices/NewPrices[1] # Applying Numeraire
    return NewPrices
end


InitialGuess = repeat([1.0], 10)
FPSolution = fixed_point(IterateOnce, InitialGuess; Algorithm = VEA)</code></pre><h2><a class="nav-anchor" id=".2-The-Perceptron-Classifier-1" href="#.2-The-Perceptron-Classifier-1">4.2 The Perceptron Classifier</a></h2><p>The perceptron is one of the oldest and simplest machine learning algorithms (Rosenblatt 1958). In its simplest form, for each observation it is applied it uses an N-dimensional vector of features x together with N+1 weights w to classify the observation as being in category one or category zero. It classifies observation j as a type one if <span>$w_0 + \sum_{i=1}^N w_i x_{i,j}  &gt; 0$</span> and as a type zero otherwise.</p><p>The innovation of the perceptron was its method for training its weights, w. This is done by looping over a set of observations that can be used for training (the &quot;training set&quot;) and for which the true category information is available. The perceptron classifies each observation. When it correctly classifies an observation no action is taken. On the other hand when the perceptron makes an error then it updates its weights with the following expressions.</p><div>\[w_{0}^\prime = w_{0} + ( d_{j} - y_{j} )\]</div><div>\[w_{i}^\prime = w_{i} + ( d_{j} - y_{j} ) x_{j,i} \hspace{1cm} \text{ for } i \geq 0\]</div><p>Where <span>$w_i$</span> is the old weight for the <span>$i$</span>&#39;th feature and <span>$w_{i}^\prime$</span> is the updated weight. <span>$x_{j,i}$</span> is the feature value for observation <span>$j$</span>&#39;s feature <span>$i$</span>, <span>$d_{j}$</span> is the category label for observation <span>$j$</span> and <span>$y_j$</span> is the perceptron&#39;s prediction for this observation’s category.</p><p>This training algorithm can be rewritten as fixed point problem. We can write a function that takes perceptron weights, loops over the data updating these weights and then returns the updated weight vector. If the perceptron classifies every observation correctly then the weights will not update and we are at a fixed point.<a href="#footnote-7">[7]</a></p><p>Most acceleration algorithms perform poorly in accelerating the convergence of this perceptron training algorithm. This is due to the perceptron often converging by a ﬁxed increment. This occurs because multiple iterates can result in the same observations being misclassiﬁed and hence the same changeintheweights. Asaresultwewillusethesimplemethodwhichisguaranteedtobeconvergent for this problem (Novikoff, 1963).</p><p>First we generate a dataset:</p><pre><code class="language-none"># Generating linearly separable data
using Distributions
using FixedPointAcceleration
using Random
using DataFrames
nobs = 20
Random.seed!(1234)
data1 = DataFrame([rand(Normal(3,2), nobs), rand(Normal(8,2), nobs), repeat([-1.0],nobs)], [:x1, :x2, :y])
data2 = DataFrame([rand(Normal(-4,2), nobs), rand(Normal(10,12), nobs), repeat([1.0],nobs)], [:x1, :x2, :y])
data  = vcat(data1,data2)
# Plotting it
using Plots
plot(data1.x1, data1.x2,seriestype=:scatter)
plot!(data2.x1, data2.x2,seriestype=:scatter)</code></pre><p>Now we write a function that will take a set of weights, update them and return the updated weights.</p><pre><code class="language-none">function IteratePerceptronWeights(w, LearningRate = 1)
    for i in 1:length(data[:y])
        target = data[i,:y]
        score = w[1] + (w[2]*data[i,:x1]) + (w[3]*data[i,:x2])
        ypred = 2*((score &gt; 0)-0.5)
        if abs(target-ypred) &gt; 1e-10
            update = LearningRate * 0.5*(target-ypred)
            w[1] = w[1] + update
            w[2] = w[2] + update*data[i,:x1]
            w[3] = w[3] + update*data[i,:x2]
        end
    end
    return(w)
end
InitialGuess = [1.0, -2.0, 0.5]
FP = fixed_point(IteratePerceptronWeights, InitialGuess; Algorithm = Simple, PrintReports = true)</code></pre><p>Only the simple method is convergent here and it is relatively slow taking 1121 iterations. We can still get a beneﬁt from accelerators however if we can modify the training algorithm to give training increments that change depending on distance from the ﬁxed point. This can be done by updating the weights by an amount proportional to a concave function of the norm of <span>$w_0 + \sum_{i=1}^N w_i x_{i,j}$</span>. Note that the instances in which the weights are not updated stay the same and hence the modiﬁed training function will result in the same set of ﬁxed points as the basic function. This is done in the next piece of code where the MPE method is used. It can be seen that there is a substantial increase in speed with only 54 iterations required by the MPE method.</p><pre><code class="language-none">function IteratePerceptronWeights(w, LearningRate = 1)
    for i in 1:length(data[:y])
        target = data[i,:y]
        score = w[1] + (w[2]*data[i,:x1]) + (w[3]*data[i,:x2])
        ypred = 2*((score &gt; 0)-0.5)
        if abs(target-ypred) &gt; 1e-10
            update = LearningRate * -sign(score) * sqrt(abs(score))
            w[1] = w[1] + update
            w[2] = w[2] + update*data[i,:x1]
            w[3] = w[3] + update*data[i,:x2]
        end
    end
    return(w)
end
InitialGuess = [1.0, -2.0, 0.5]
FP = fixed_point(IteratePerceptronWeights, InitialGuess; Algorithm = MPE, PrintReports = true)</code></pre><p>We can verify that the set of weights represented by the fixed_point function does correctly seperate the data by plotting it:</p><pre><code class="language-none"># Plotting new seperation line
x1 = -6.0:0.1:6.0
w = FP.FixedPoint_
x2_on_sep_line = (-w[1] .- w[2] .* x1) ./ w[3]
plot!(x1,x2_on_sep_line, label =&quot;SeperationLine&quot;)</code></pre><div class="footnote" id="footnote-7"><a href="#footnote-7"><strong>[7]</strong></a><p>Note that for perceptrons there are always uncountably many such fixed points where the perceptron correctly classifies the entire training set and will not further update. On the other hand it is possible that the data is not linearly separable in which case there may be no fixed point and the weights will continue to update forever.</p></div><h2><a class="nav-anchor" id=".3-Expectation-Maximisation-1" href="#.3-Expectation-Maximisation-1">4.3 Expectation Maximisation</a></h2><p>Consider we have a set of data which has come from two different multivariate normal distributions. There is a probability <span>$\tau$</span> that a datapoint comes from the first multivariate distribution.</p><pre><code class="language-none"># Generating data from two two-dimensional gaussian processes
using Distributions
using FixedPointAcceleration
using Random
using DataFrames
true_tau = 0.6
nobs_1 = 400
nobs_2 = convert(Int, round(nobs_1 * ((1-true_tau)/true_tau)))
Random.seed!(1234)
mu_1 = [0.0,8.0]
cov_1 = [2.0,0.5,2.0]
covar_1 = Symmetric([cov_1[1] cov_1[2]; cov_1[2] cov_1[3]])
md_1 = MultivariateNormal(mu_1,covar_1)
mu_2 = [-4.0,10.0]
cov_2 = [2.0,-0.75,12.0]
covar_2 = Symmetric([cov_2[1] cov_2[2]; cov_2[2] cov_2[3]])
md_2 = MultivariateNormal(mu_2,covar_2)

rands_from_1 = transpose(rand(md_1, nobs_1))
rands_from_2 = transpose(rand(md_2, nobs_2))
data1 = DataFrame([rands_from_1[:,1], rands_from_1[:,2]], [:x1, :x2])
data2 = DataFrame([rands_from_2[:,1], rands_from_2[:,2]], [:x1, :x2])
dd  = vcat(data1,data2)
# Plotting it:
plot(data1.x1, data1.x2,seriestype=:scatter)
plot!(data2.x1, data2.x2,seriestype=:scatter)</code></pre><p>Now we want to estimate the parameter <span>$\tau$</span>, the means (represented above by mu<em>1 and mu</em>2) and the covariance matrices (represented above by cov<em>1, cov</em>2) using only the realised datapoints in the DataFrame called dd. We will refer to these parameters as <span>$\theta$</span>.</p><p>If we knew from which distribution each datapoint came, the above task would be considerably easier. We could separate the data and for each use <a href="https://en.wikipedia.org/wiki/Estimation_of_covariance_matrices">standard techniques</a> to find the expected mean and covariance matrix. We do not know from which distribution each datapoint came from however. We could use a guess for <span>$\theta$</span> to estimate the probabilities of each datapoint coming from each distribution however (and call this vector of estimates by <span>$Z$</span>). Then we could choose maximum likelihood estimates of <span>$\theta$</span> using our estimates of <span>$Z$</span> in the likelihood expression. This is the EM approach. Note that it lends itself well to fixed point acceleration - We can write a function that given <span>$\theta$</span> creates estimated probabilities of source distribution for each datapoint (<span>$Z$</span>) and uses these in a maximum likelihood expression to improve the estimate of <span>$\theta$</span>.</p><p>In this multivariate gaussian case there are simple expressions to choose parameters to maximise the likelihood. These are recounted on the <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">wikipedia article on expectation maximisation</a> and are used below:</p><pre><code class="language-none">function z_estimate_given_theta(x::Array{Float64,1}, md_1::MultivariateNormal, md_2::MultivariateNormal, tau::Float64)
    pdf_1 = pdf(md_1, x)
    pdf_2 = pdf(md_2, x)
    return tau*pdf_1 / (tau*pdf_1 + (1-tau)*pdf_2)
end

function update_tau(Z::Array{Float64,1})
    return mean(Z)
end

function update_mu(dd::DataFrame, Z::Array{Float64,1})
    X = convert(Array{Float64,2}, dd[[:x1, :x2]])
    sum_Z = sum(Z)
    updated_mu = (transpose(Z) * X) ./sum_Z
    return vec(updated_mu)
end

function update_cov(dd::DataFrame, updated_mu::Array{Float64,1}, Z::Array{Float64,1})
    X_minus_mu = convert(Array{Float64,2}, dd[[:x1, :x2]]) .- transpose(updated_mu)
    sum_Z = sum(Z)
    updated_cov = (transpose(Z .* X_minus_mu) * X_minus_mu) ./sum_Z
    return [updated_cov[1,1], updated_cov[1,2], updated_cov[2,2]]
end

function update_theta(theta::Array{Float64,1}, dd::DataFrame)
    # We will use the convention that theta&#39;s 11 entries are (mu_1, cov_1, mu_2, cov_2, tau). First unpacking theta:
    mu_1    = theta[[1,2]]
    cov_1   = theta[[3,4,5]]
    covar_1 = Symmetric([cov_1[1] cov_1[2]; cov_1[2] cov_1[3]])
    md_1 = MultivariateNormal(mu_1,covar_1)
    mu_2    = theta[[6,7]]
    cov_2   = theta[[8,9,10]]
    covar_2 = Symmetric([cov_2[1] cov_2[2]; cov_2[2] cov_2[3]])
    md_2 = MultivariateNormal(mu_2,covar_2)
    tau     = theta[11]
    # Getting Z
    Z = Array{Float64,1}(undef,size(dd)[1])
    for i in 1:size(dd)[1]
        Z[i] = z_estimate_given_theta([dd[i,:x1], dd[i,:x2]], md_1, md_2, tau)
    end

    # Updating Tau
    updated_tau = update_tau(Z)
    # Updating mu1
    updated_mu_1 = update_mu(dd,Z)
    updated_mu_2 = update_mu(dd, 1 .- Z)
    # Updating Cov
    updated_cov_1 = update_cov(dd, updated_mu_1, Z)
    updated_cov_2 = update_cov(dd, updated_mu_2, 1 .- Z)
    # Returning theta
    updated_theta = vcat(updated_mu_1, updated_cov_1, updated_mu_2, updated_cov_2, updated_tau)
    return updated_theta
end</code></pre><p>Now we can come up with a choice for an initial guess based on eyeballing the plotted data. We can then put it into the fixed_point function to get ML estimates of these distributional parameters as well as <span>$\tau$</span>:</p><pre><code class="language-none">InitialGuess = [0.5, 7.5, 2.0, 0.0, 2.0, -5.0, 7.5, 2.0, 0.0, 10.0, 0.5]
fp_anderson = fixed_point(x -&gt; update_theta(x,dd), InitialGuess; Algorithm = Anderson, PrintReports = true)
fp_simple   = fixed_point(x -&gt; update_theta(x,dd), InitialGuess; Algorithm = Simple, PrintReports = true)</code></pre><p>We can see that the Anderson method only takes 15 iterations while the simple method takes 80. By checking the generated fixedpoint against the data generation process it can also be verified that the fixedpoint we find provides quite good estimates.</p><h2><a class="nav-anchor" id=".4-A-consumption-smoothing-problem-1" href="#.4-A-consumption-smoothing-problem-1">4.4 A consumption smoothing problem</a></h2><p>Consider an infinitely lived consumer that has a budget of <span>$B_t$</span> at time <span>$t$</span> and a periodic income of <span>$1$</span>. She has a periodic utility function given by <span>$\epsilon_t x_t^\delta$</span>, where <span>$x_t$</span> is spending in period <span>$t$</span> and <span>$\epsilon_t$</span> is the shock in period <span>$t$</span> drawn from some stationary nonnegative shock process with pdf <span>$f(\epsilon)$</span> defined on the interval <span>$[y,z]$</span>. The problem for the consumer in period <span>$t$</span> is to maximise their value function:</p><div>\[V(B_t | \epsilon_{t}) =  \max_{0 &lt; x_t &lt; B_t} \hspace{0.5cm} \epsilon_t x_t^\delta + \beta \int_y^z V(B_{t+1} | \epsilon) f(\epsilon)d\epsilon\]</div><p>Where <span>$\beta$</span> is a discounting factor and <span>$B_{t+1} = 1 + B_t - x_t$</span>.</p><p>Our goal is that we want to find a function that gives the optimal spending amount, <span>$\hat{x}(B_t, \epsilon_t)$</span>,  in period <span>$t$</span> which is a function of the shock magnitude <span>$\epsilon_{t}$</span> and the saved budgets <span>$B_{t}$</span> in this period. If we knew the function <span>$\int_y^z V(B_{t+1} \vert \epsilon) f(\epsilon)d\epsilon$</span> then we could do this by remembering <span>$B_{t+1} = 1 + B_t - x_t$</span> and using the optimisation:</p><div>\[\hat{x}(B_t, \epsilon_t) = \text{argmax}_{0 &lt; x_t &lt; B_t} \hspace{0.5cm} \epsilon_t x_t^\delta + \beta \int_y^z V(B_{t+1} | \epsilon) f(\epsilon)d\epsilon\]</div><p>So now we need to find the function <span>$E_t[ V(B_{t+1})]$</span>. Note as the shock process is stationary, the consumer lives forever and income is always 1, <span>$E_t[ V(B_{t+1})]$</span> will not vary with <span>$t$</span>. As a result we will rewrite it as simply <span>$f(b)$</span>.</p><p>Now we will construct a vector containing a grid of budget values, <span>$\bar{b}$</span>, for instance <span>$\bar{b} = [0, 0.01,0.02, ... , 5]$</span> (we will use bars to describe approximations gained from this grid). If we could then approximate a vector of the corresponding function values, <span>$\bar{f}$</span>,  so we had for instance <span>$\bar{f} = [f(0), f(0.01), f(0.02), ... , f(5)]$</span> then we could approximate the function by constructing a spline <span>$\bar{f}(b)$</span> between these points. Then we can get the function:</p><div>\[\bar{x}(B_t, \epsilon_t) = \text{argmax}_{0 &lt; x &lt; B_t} \hspace{0.5cm} \epsilon_t x_t^{\delta} + \bar{f}(B_{t} - x)]\]</div><p>So this problem reduces to finding the vector of function values at a discrete number of points, <span>$\bar{f}$</span>. This can be done as a fixed point problem. We can first note that this problem is a contraction mapping problem. In this particular example this means that if we define a sequence <span>$\bar{f}_0 = f_0$</span> where <span>$f_0$</span> is some initial guess and <span>$f_i = g(f_{i-1})$</span> where <span>$g$</span> is given by the IterateOnce function below then this sequence will be convergent. Convergence would be slow however so below we will actually use the Anderson method:</p><pre><code class="language-none">using Distributions
using FixedPointAcceleration
using HCubature
using Optim
using Random
using SchumakerSpline
delta = 0.2
beta = 0.95
periodic_income = 1.0
shock_var = 1.0
shock_process = LogNormal(0.0, shock_var)
BudgetStateSpace = vcat( collect(0:0.015:periodic_income), collect(1.05:0.05:(3*periodic_income)))
InitialGuess = sqrt.(BudgetStateSpace)

function ValueGivenShock(Budget::Float64, epsilon::Float64, NextValueFunction::Schumaker)
    opt = optimize(x -&gt;  -1.0*(epsilon*(x^delta) + beta*evaluate(NextValueFunction, Budget - x + periodic_income)), 0.0, Budget)
    return -1.0 * opt.minimum
end

function ExpectedUtility(Budget::Float64, NextValueFunction::Schumaker)
    if Budget &gt; 0.00001
        integ = hcubature(epsilon-&gt; ValueGivenShock(Budget, epsilon[1], NextValueFunction)* pdf(shock_process, epsilon[1]), [quantile(shock_process,0.0001)], [quantile(shock_process, 0.9999)])
        return integ[1]
    else
        return beta * evaluate(NextValueFunction, periodic_income)
    end
end

function OneIterateBudgetValues(BudgetValues::Array{Float64,1})
    NextValueFunction = Schumaker(BudgetStateSpace, BudgetValues)
    new_budget_values = zeros(length(BudgetStateSpace))
    for i in 1:length(BudgetStateSpace)
        new_budget_values[i] = ExpectedUtility(BudgetStateSpace[i], NextValueFunction)
    end
    return new_budget_values
end

fp_anderson = fixed_point(OneIterateBudgetValues, InitialGuess; Algorithm = Anderson, PrintReports = true)
fp_simple   = fixed_point(OneIterateBudgetValues, InitialGuess; Algorithm = Simple, PrintReports = true)</code></pre><p>This takes 22 iterates with the Anderson algorithm which is drastically better than the 459 iterates it takes with the simple method.</p><footer><hr/><a class="previous" href="../3_UsingAdvice/"><span class="direction">Previous</span><span class="title">3.  Using the FixedPointAcceleration package</span></a><a class="next" href="../99_refs/"><span class="direction">Next</span><span class="title">References</span></a></footer></article></body></html>
