<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>FixedPointAcceleration.jl · FixedPointAcceleration</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>FixedPointAcceleration</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>FixedPointAcceleration.jl</a><ul class="internal"><li class="toplevel"><a class="toctext" href="#Fixed-point-acceleration-1">1 Fixed point acceleration</a></li></ul></li><li><a class="toctext" href="2_Algorithms/">2 Acceleration algorithms</a></li><li><a class="toctext" href="3_UsingAdvice/">3.  Using the FixedPoint package</a></li><li><a class="toctext" href="99_refs/">References</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>FixedPointAcceleration.jl</a></li></ul><a class="edit-page" href="https://github.com/s-baumann/FixedPointAcceleration.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>FixedPointAcceleration.jl</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="FixedPointAcceleration.jl-1" href="#FixedPointAcceleration.jl-1">FixedPointAcceleration.jl</a></h1><p>Fixed point finders are conceptually similar to both optimisation and root finding algorithms but thus far implementations of fixed point finders have been rare in Julia. In some part this is likely because there is often an obvious method to find a fixed point by merely feeding a guessed fixed point into a function, taking the result and feeding it back into the function. By doing this repeatedly a fixed point is often found. This method (that we will call the &quot;Simple&quot; method) is often convergent but it is also often slow which can be prohibitive when the function itself is expensive.</p><p><strong>FixedPointAcceleration.jl</strong> aims to provide fixed point acceleration algorithms that can be much faster than the simple method. In total eight algorithms are implemented. The first is the simple method as described earlier. There are also the Newton, Aitken and Scalar Epsilon Algorithm (SEA) methods that are designed for accelerating the convergence of scalar sequences. Four algorithms for accelerating vector sequences are also implemented including the Vector Epsilon Algorithm (VEA), two minimal polynomial algorithms (MPE and RRE)  and Anderson acceleration.</p><p>In this paper section 1 starts by with a brief explanation of fixed points before section 2 describes the acceleration algorithms provided by <strong>FixedPointAcceleration.jl</strong>. Here the goal is  to illustrate the logic underling each algorithm so users can better choose which suits their problem. Readers interested in the underlying mathematics are referred to the original papers. Section 3 then illustrates a few features of the package that enable users to better track the progress of an algorithm while it is running and switch algorithms if desired before a fixed point is found.</p><p>Section 4 then presents several applications of these fixed point algorithms in economics, asset pricing and machine learning. Finally section 5 presents a convergence comparison showing how many iterations each algorithm takes in bringing each problem to its fixed point for each of the applications presented in section 4.</p><h1><a class="nav-anchor" id="Fixed-point-acceleration-1" href="#Fixed-point-acceleration-1">1 Fixed point acceleration</a></h1><p>A fixed point problem is one where we look for a vector, <span>$\hat{X} \in \Re^N$</span>, so that for a given function <span>$f: \Re^N \rightarrow \Re^N$</span> we have:</p><div>\[f(\hat{X}) = \hat{X}\]</div><p>If <span>$f: \Re^1 \rightarrow \Re^1$</span> and thus any solution <span>$\hat{X}$</span> will be a scalar then one way to solve this problem would be to use a rootfinder on the function <span>$g(x) = f(x) - x$</span> or to use an optimiser to minimise <span>$h(x) = (f(x) - x)^2$</span>. These techniques will not generally work however if <span>$f : N^a \rightarrow N^a$</span> where <span>$a$</span> is large. Consider for instance using a multidimensional Newtonian optimiser to minimise <span>$h(x) = (f(x) - x)^2$</span>. The estimation of gradients for each individual dimension may take an infeasibly long time. In addition this method may not make use all available information. Consider for instance that we know that the solution for <span>$x$</span> will be an increasing vector (so <span>$x_i &gt; x_j$</span> for any entries of <span>$x$</span>  with <span>$i &gt; j$</span>) but has many entries. This information can be preserved and used in the vector acceleration algorithms that we present but would be more difficult to exploit in a standard optimisation algorithm.</p><p><strong>FixedPointAcceleration.jl</strong> implements eight algorithms for finding fixed points. The first algorithm implemented in this package is the &quot;simple&quot; method which merely takes the output of a function and feeds it back into the function. For instance starting with a guess of <span>$x_0$</span>, the next guess will be <span>$x_1 = f(x_0)$</span>. The guess after that will be <span>$x_2 = f(x_1)$</span> and so on. In some conditions <span>$f$</span> will be a contraction mapping and so the simple method will be guaranteed to converge to a unique fixed point (Stokey, Lucas &amp; Prescott 1989). Even when this is the case however the simple method may only converge slowly which can be inconvenient. The other seven methods this package implements are designed to be faster than the simple method but may not be convergent for every problem.</p><ul><li><a href="2_Algorithms/#Acceleration-algorithms-1">2 Acceleration algorithms</a></li><ul><li><a href="2_Algorithms/#.1-Newton-acceleration-1">2.1 Newton acceleration</a></li><li><a href="2_Algorithms/#.2-Aitken-acceleration-1">2.2 Aitken acceleration</a></li><li><a href="2_Algorithms/#.3-Epsilon-algorithms-1">2.3 Epsilon algorithms</a></li><li><a href="2_Algorithms/#.4-Minimal-polynomial-algorithms-1">2.4 Minimal polynomial algorithms</a></li><li><a href="2_Algorithms/#.5-Anderson-acceleration-1">2.5 Anderson acceleration</a></li></ul><li><a href="3_UsingAdvice/#.-Using-the-FixedPoint-package-1">3.  Using the FixedPoint package</a></li><ul><li><a href="3_UsingAdvice/#.1-Basic-examples-of-using-FixedPoint-1">3.1 Basic examples of using FixedPoint</a></li><li><a href="3_UsingAdvice/#.2-Easily-changing-algorithm-1">3.2 Easily changing algorithm</a></li><li><a href="3_UsingAdvice/#.4-Graceful-error-handling-1">3.4 Graceful error handling</a></li><li><a href="3_UsingAdvice/#.5-Convergence-by-constant-increments-1">3.5 Convergence by constant increments</a></li></ul><li><a href="99_refs/#References-1">References</a></li><li><a href="#FixedPointAcceleration.jl-1">FixedPointAcceleration.jl</a></li><li><a href="#Fixed-point-acceleration-1">1 Fixed point acceleration</a></li></ul><footer><hr/><a class="next" href="2_Algorithms/"><span class="direction">Next</span><span class="title">2 Acceleration algorithms</span></a></footer></article></body></html>
